{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras imports\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.applications.vgg19 import VGG19, preprocess_input\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "from keras.applications.mobilenet import MobileNet, preprocess_input\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.models import model_from_json\n",
    "from keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import h5py\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('conf/conf.json') as f:\n",
    "\tconfig = json.load(f)\n",
    "\n",
    "# config variables\n",
    "model_name \t\t= config[\"model\"]\n",
    "weights \t\t= config[\"weights\"]\n",
    "include_top \t= config[\"include_top\"]\n",
    "train_path \t\t= config[\"train_path\"]\n",
    "features_path \t= config[\"features_path\"]\n",
    "labels_path \t= config[\"labels_path\"]\n",
    "test_size \t\t= config[\"test_size\"]\n",
    "results \t\t= config[\"results\"]\n",
    "model_path \t\t= config[\"model_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start time\n",
    "print (\"[STATUS] start time - {}\".format(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")))\n",
    "start = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name == \"inceptionv3\"\n",
    "base_model = InceptionV3(include_top=False, weights=weights, input_tensor=Input(shape=(299,299,3)))\n",
    "model = Model(input=base_model.input, output=base_model.get_layer('mixed10').output)\n",
    "image_size = (299, 299)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to training dataset\n",
    "train_labels = os.listdir(train_path)\n",
    "\n",
    "# encode the labels\n",
    "print (\"[INFO] encoding labels...\")\n",
    "le = LabelEncoder()\n",
    "le.fit([tl for tl in train_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables to hold features and labels\n",
    "features = []\n",
    "labels   = []\n",
    "\n",
    "# loop over all the labels in the folder\n",
    "count = 1\n",
    "for i, label in enumerate(train_labels):\n",
    "\tcur_path = train_path + \"/\" + label\n",
    "\tcount = 1\n",
    "\tfor image_path in glob.glob(cur_path + \"/*.jpg\"):\n",
    "\t\timg = image.load_img(image_path, target_size=image_size)\n",
    "\t\tx = image.img_to_array(img)\n",
    "\t\tx = np.expand_dims(x, axis=0)\n",
    "\t\tx = preprocess_input(x)\n",
    "\t\t# feature = model.predict(x)\n",
    "\t\tfeature = model.predict(x=x)\n",
    "\t\t# feature = model.predict(x)\n",
    "\t\tflat = feature.flatten()\n",
    "\t\tfeatures.append(flat)\n",
    "\t\tlabels.append(label)\n",
    "\t\tprint (\"[INFO] processed - \" + str(count))\n",
    "\t\tcount += 1\n",
    "\tprint (\"[INFO] completed label - \" + label)\n",
    "\n",
    "# encode the labels using LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le_labels = le.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the shape of training labels\n",
    "print (\"[STATUS] training labels: {}\".format(le_labels))\n",
    "print (\"[STATUS] training labels shape: {}\".format(le_labels.shape))\n",
    "\n",
    "# save features and labels\n",
    "h5f_data = h5py.File(features_path, 'w')\n",
    "h5f_data.create_dataset('dataset', data=np.array(features))\n",
    "\n",
    "h5f_label = h5py.File(labels_path, 'w')\n",
    "h5f_label.create_dataset('dataset', data=np.array(le_labels))\n",
    "\n",
    "h5f_data.close()\n",
    "h5f_label.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model and weights\n",
    "model_json = model.to_json()\n",
    "with open(model_path + str(test_size) + \".json\", \"w\") as json_file:\n",
    "\tjson_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights\n",
    "model.save_weights(model_path + str(test_size) + \".h5\")\n",
    "print(\"[STATUS] saved model and weights to disk..\")\n",
    "\n",
    "print (\"[STATUS] features and labels saved..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end time\n",
    "end = time.time()\n",
    "print (\"[STATUS] end time - {}\".format(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
